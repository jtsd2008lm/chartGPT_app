继续学习强化学习 Q-learning算法，这次我想实现一个比上次“迷宫”再复杂一点的。

还是问c老师：

![](E:\chartGPT_app\Q_learning-BlackJack\images\1.png)

![](E:\chartGPT_app\Q_learning-BlackJack\images\2.png)

棋类游戏貌似太复杂，还是选个简单的纸牌类游戏吧。不过其实我没玩过21点，还特地去了解了下21点的游戏规则。

![](E:\chartGPT_app\Q_learning-BlackJack\images\3.png)



c老师给出的代码很好，但是有几个问题：

1，如果输出太长就被截断了，再让它继续代码就乱套了

2，截断后继续原来的话题，对话太多以后，c老师出现前言不搭后语情况。我对强化学习，python语法都不很是很熟，经常被搞晕。

不过，这个人机交互的程序比较简单，折腾了半天，搞定了

![](E:\chartGPT_app\Q_learning-BlackJack\images\4.png)



人机交互的程序简单。接下来如果训练一个小机器人来玩21点，并测试效果，那就难了。

开始我想用“迷宫”那样的方式做一个矩阵，状态分别是玩家点数，庄家点数等等，但是貌似不行：

![](E:\chartGPT_app\Q_learning-BlackJack\images\5.png)

神经网络，经验回放，Q-learning都是我不熟悉的概念。我问c老师给我生成了代码，但是看不懂代码背后的意思，运行报错，搞得不报错后又不知道结果对不对。

看来还是需要系统得学习下啊！
